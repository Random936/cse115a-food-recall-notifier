* CSE115A - Food Recall Notifier

* Vision Statement

Food Recall Notifier will be created to notify users of any recalled food quickly and through their phone based on the [[https://www.fda.gov/safety/recalls-market-withdrawals-safety-alerts][FDA website]]. In order to more quickly alert the user of recall with minimal time impact, a mobile application will be used allowing for bar code scanning.

* Components

+ *Android/IOS Mobile Application:*
+ *Backend API:*
+ *Backend Database:*
+ *FDA Web Scraper:*

* Required Features

** TODO UPC Number Lookup

The client most importantly must incorporate the ability to lookup a UPC number and return any recall information if it exists. This is the core functionality of the app.

** TODO Barcode Scanner

The ability to scan a barcode using the phone's camera should be implemented to allow for the easy lookup of UPC numbers. Ideally this should be implemented on the client side to avoid unnecessary computation on the backend.

** TODO Real Time Search

The IOS/Android application should provide a responsive search functionality such that when the search query is changed, the results are automatically updated to reflect the current search term. This will require the ability to search for partial UPC numbers on the backend.

** TODO Display of Recalled Item

This display should include:
+ The UPC Number
+ Image of the recalled item
+ Date of recall
+ Reason for Announcement
+ Brand Name
+ Item Being Recalled

* Interfaces

** Web Scraper

There are two interfaces defined within the web scraper to logically separate crawling and parsing. The intention of adding a separation here is to allow for better modularity when incorporating more recall sources or crawling methods.

*** Web Crawler

#+begin_src python
class WebCrawler:
    def __init__(self):
        pass

    # TODO
#+end_src

*** Web Parser

#+begin_src python
class WebParser:
    def __init__(self):
        pass

    # TODO
#+end_src

** Database Interfaces

*** Database

#+begin_src python
class Database:
    def __init__(self, database):
        pass
#+end_src

*** DBSearcher

This could logically split on the methods used to lookup databases. For example, a DBSearcher could be used to separate the logic between UPC lookups and barcode lookups. This could also be used to search for other fields such as expiration date, etc.

#+begin_src python
class DBSearcher:
    def __init__(self, database):
        pass

    # Returns an array of records from a database query.
    def search(self, query) -> list:
        raise NotImplementedError

    # Returns a single record from a query.
    def query(self, query) -> dict:
        raise NotImplementedError
#+end_src

* API Routes

** Client

No authentication should be required for any of the client API routes.

*** ~/search/<UPC>~

This route will search for any matching UPC number given a specific UPC or a partial UPC. It will return a list of UPC records with a brief set of data.

**** Example Success Response

#+begin_src json
[
    {"upc": "123123123123", "recall_reason": "salmonella", "date_posted": 1736785262},
    {"upc": "123123123123", "recall_reason": "salmonella", "date_posted": 1736785262},
    {"upc": "123123123123", "recall_reason": "salmonella", "date_posted": 1736785262}
]
#+end_src

**** Example Failed Response

#+begin_src json
[]
#+end_src

*** ~/query/<UPC>~

This route will query a single UPC and return the first matching record found with a full set of the scraped data.

**** Example Success Response

#+begin_src json
{
    "upc": "123123123123",
    "item_name": "Raw Chicken 12 ct.",
    "brand_name": "Raw Chicken Inc.",
    "expiration_date": "2025/01/13",
    "recall_reason": "salmonella",
    "date_posted": 1736785262
}
#+end_src

**** Example Failed Response

#+begin_src json
{"error": "UPC not found"}
#+end_src

*** ~/image/<UPC>~

This route will query a single UPC and return the first matching record found with a full set of the scraped data.

**** Example Success Response

The response will be the image itself similar to a GET request for said image.

**** Example Failed Response

Failed response will be a non 200 HTTP status code (ex. 404, 500).


** Web Scrapers

Authentication is required for all web scraper API routes.

*** ~/jobs/query~

This route is used to assign a job to an idle web scraper. Web scrapers will query the backend server for jobs at a constant time interval (eg. 5 minutes) or after completing a job.

**** Addressing Lost Jobs

To work around the problem of jobs being allocated and never completed, once the job is assigned, the job will be marked "in progress" and will start a timer awaiting the results. If the job reaches a timeout (due to a failure for example), it will once again be added to the pending job queue and later reassigned.

*** ~/jobs/finish~

This route will be used to mark a job complete and store any results generated from said job.

*** ~/jobs/pending~

Not necessarily a required route, though could be helpful for determining the number of back logged jobs. A GET request to route will return an integer with the number of pending jobs.

* Notable Dependencies

+ SQL - Backend Database
+ Flask - Backend API
+ BeautifulSoup - Web Scrapers

* Security Considerations

** API Keys

In our current plan, the client will never write to the database and will only ever read based on a UPC number. To prevent a malicious request from writing to the database using the same API calls used by the web scraper, we will need to employ API keys.
